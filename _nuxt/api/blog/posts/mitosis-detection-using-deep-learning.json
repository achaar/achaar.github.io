{
  "id": "mitosis-detection-using-deep-learning",
  "slug": "mitosis-detection-using-deep-learning",
  "highlightedLanguages": [],
  "source": "---\nphoto: /images/mitosis.jpg\ndate: 2018-11-01\ntags:\n  - project\n---\n# Mitosis Detection using Deep Learning\n\n A Mitosis is a pretty rare phenomenon and and when its size is compared to the size of the breast cancer histology images,  we are able to see why it is a needle in a haystack kind of a problem.  Add to that the varied shapes it occurs in, it becomes even more challenging. We started with the Theano library and implemented a CNN model which was derived from the state of the art paper having the same title. Since, it did not work well because of the skewed data set, we tried to use Stain Segmentation [ Work of Abhishek Vahadne and team at IITG]. It had little to no effect on the accuracy of our results. We finally found out in January, 2016 that our network had the problem of dead weights due to random initialization. This was only possible because the CS231N lectures came out in December, 2015 and I used to follow them. We were very lucky that this problem was discussed in CVPR 2015 and therefore it was mentioned in the Stanford lectures. We also incorporated some other newer learning rules like AdaGrad and Adam update, which helped us omit tuning the learning rate. After this our model worked and we were able to achieve the results with a single CNN, where as the original paper used 2 cascaded CNNs. The F-score calculated for pixel classification was 0.51, with 0.42 precision and 0.63 Recall.\n\nRepository and Poster Link: https://github.com/znck/mitosis-detection\n",
  "rendered": "<h1>Mitosis Detection using Deep Learning</h1>\n<p>A Mitosis is a pretty rare phenomenon and and when its size is compared to the size of the breast cancer histology images,  we are able to see why it is a needle in a haystack kind of a problem.  Add to that the varied shapes it occurs in, it becomes even more challenging. We started with the Theano library and implemented a CNN model which was derived from the state of the art paper having the same title. Since, it did not work well because of the skewed data set, we tried to use Stain Segmentation [ Work of Abhishek Vahadne and team at IITG]. It had little to no effect on the accuracy of our results. We finally found out in January, 2016 that our network had the problem of dead weights due to random initialization. This was only possible because the CS231N lectures came out in December, 2015 and I used to follow them. We were very lucky that this problem was discussed in CVPR 2015 and therefore it was mentioned in the Stanford lectures. We also incorporated some other newer learning rules like AdaGrad and Adam update, which helped us omit tuning the learning rate. After this our model worked and we were able to achieve the results with a single CNN, where as the original paper used 2 cascaded CNNs. The F-score calculated for pixel classification was 0.51, with 0.42 precision and 0.63 Recall.</p>\n<p>Repository and Poster Link: <a href=\"https://github.com/znck/mitosis-detection\">https://github.com/znck/mitosis-detection</a></p>\n",
  "attributes": {
    "photo": "/images/mitosis.jpg",
    "date": "2018-11-01T00:00:00.000Z",
    "tags": [
      {
        "id": "project",
        "name": "project"
      }
    ],
    "title": "Mitosis Detection using Deep Learning",
    "updated_at": "2020-01-09T06:04:54.289Z",
    "description": "A Mitosis is a pretty rare phenomenon and and when its size is compared to the size of the breast cancer histology images,  we are able to see why it is a needle in a haystack kind of a problem.  Add to that the varied shapes it occurs in, it becomes even more challenging. We started with the Theano library and implemented a CNN model which was derived from the state of the art paper having the same title. Since, it did not work well because of the skewed data set, we tried to use Stain Segmentation [ Work of Abhishek Vahadne and team at IITG]. It had little to no effect on the accuracy of our results. We finally found out in January, 2016 that our network had the problem of dead weights due to random initialization. This was only possible because the CS231N lectures came out in December, 2015 and I used to follow them. We were very lucky that this problem was discussed in CVPR 2015 and therefore it was mentioned in the Stanford lectures. We also incorporated some other newer learning rules like AdaGrad and Adam update, which helped us omit tuning the learning rate. After this our model worked and we were able to achieve the results with a single CNN, where as the original paper used 2 cascaded CNNs. The F-score calculated for pixel classification was 0.51, with 0.42 precision and 0.63 Recall."
  },
  "title": "Mitosis Detection using Deep Learning",
  "description": "A Mitosis is a pretty rare phenomenon and and when its size is compared to the size of the breast cancer histology images,  we are able to see why it is a needle in a haystack kind of a problem.  Add to that the varied shapes it occurs in, it becomes even more challenging. We started with the Theano library and implemented a CNN model which was derived from the state of the art paper having the same title. Since, it did not work well because of the skewed data set, we tried to use Stain Segmentation [ Work of Abhishek Vahadne and team at IITG]. It had little to no effect on the accuracy of our results. We finally found out in January, 2016 that our network had the problem of dead weights due to random initialization. This was only possible because the CS231N lectures came out in December, 2015 and I used to follow them. We were very lucky that this problem was discussed in CVPR 2015 and therefore it was mentioned in the Stanford lectures. We also incorporated some other newer learning rules like AdaGrad and Adam update, which helped us omit tuning the learning rate. After this our model worked and we were able to achieve the results with a single CNN, where as the original paper used 2 cascaded CNNs. The F-score calculated for pixel classification was 0.51, with 0.42 precision and 0.63 Recall.",
  "photo": "/images/mitosis.jpg",
  "keywords": [
    "project"
  ],
  "published_at": "2018-11-01T00:00:00.000Z",
  "updated_at": "2020-01-09T06:04:54.289Z",
  "year": 2018,
  "month": 11,
  "day": 2,
  "next": {
    "id": "adhd",
    "slug": "adhd",
    "collection": null,
    "title": "Attention Deficit Hyperactivity Disorder (ADHD) Related Resources",
    "description": "Wikipedia: https://en.wikipedia.org/wiki/Attention_deficit_hyperactivity_disorder",
    "photo": "/images/adhd.jpg",
    "published_at": "2018-11-01T00:00:00.000Z"
  },
  "prev": {
    "id": "pedestrian-detection-using-deep-learning",
    "slug": "pedestrian-detection-using-deep-learning",
    "collection": null,
    "title": "Pedestrian Detection using Deep Learning @ Summer Research Internship at Hanyang University, Korea",
    "description": "I started by reading research papers to understand what type of classifier would be required for the problem. After reading a few papers, I picked a then state of the art paper from 2013 with the title Joint Deep Learning for Pedestrian Detection. I learned about the challenges related to Object Detection, in particular, about Deformation and Occlusion Handling. The objective was to detect a pedestrian in a given window and the novelty of the paper was to learn all the parameters related to feature extraction, deformation & occlusion handling, and the classifier simultaneously, whereas these were obtained separately in the previous approaches. What was interesting about the approach was that the filters in the second layer were of different sizes to account for the different parts and their occlusion statuses. In the next layer, a deformation model was learned based on the quadratic constraint of deformation, which added the weighted sum of deformation maps to the part detection matrices obtained from the second layer, and then the result was max-pooled to get a Part score. 20 Parts were divided into 3 levels, consisting of arms & legs (level I), torso(level II), one half of the body(level III), etc. Since, the parts at a lower level are related to parts at the higher level, for example, hands are part of the torso, Visibility and Classification of the parts was modeled keeping this in mind. Therefore, parameters from lower levels also contributed to the detection of objects at higher levels. A sigmoid function was used as an activation function in the classification model. The learning was done by Back Propagating the error obtained on the log loss.",
    "photo": "/images/intern-cover.jpg",
    "published_at": "2018-11-01T00:00:00.000Z"
  }
}